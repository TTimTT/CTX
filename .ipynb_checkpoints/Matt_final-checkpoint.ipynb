{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Captain Cook: the fabulous recipes explorator\n",
    "\n",
    "\n",
    "\n",
    "Objectives:\n",
    "\n",
    "- [X] Create our own JSON map to plot informations about the recipes by region more specifically\n",
    "- [Pending] Make the map more interactive and correct the colormap issue\n",
    "- [Pending] Finish the ingredients list cleaning\n",
    "- [X] Use statistical properties of the English language or Levenshtein distance\n",
    "- [Pending] Create a user friendly recipe finder \n",
    "\n",
    "\n",
    "Bonus:\n",
    "\n",
    "- Try to compute missing nutritional informations\n",
    "- Find meaningful substitutions for ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'wordcloud'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-89edcd7c0084>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mwordcloud\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWordCloud\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSTOPWORDS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImageColorGenerator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'wordcloud'"
     ]
    }
   ],
   "source": [
    "# Basic imports\n",
    "import re\n",
    "import os.path\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "\n",
    "# Map-related imports\n",
    "import json\n",
    "import branca\n",
    "import folium\n",
    "from pandas.io.json import json_normalize\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "# Plot-related imports\n",
    "import seaborn as sns\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "from ipywidgets.embed import embed_minimal_html\n",
    "\n",
    "from PIL import Image\n",
    "#from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General parameters\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn')#switch to seaborn style\n",
    "plt.rcParams[\"figure.figsize\"] = [16,10]\n",
    "\n",
    "DATA_FOLDER = './data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Loading\n",
    "  \n",
    "The Data has been fetched and cleaned with `BASH`scripts, please look in the *dataCleaning* section to understand how this was achieved.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Home made fetched dataset:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing ingredients to Pandas DF\n",
    "allrecipes_df = pd.read_csv(DATA_FOLDER + 'allrecipes.csv', sep='\\t',  header=None, encoding = \"utf-8\")\n",
    "allrecipes_df.columns = ['ID', 'Region', 'Title', 'Ingredients', 'kcal', 'carb', 'fat', 'protein', 'sodium', 'cholesterol']\n",
    "\n",
    "# Bug?? need to convert into numeric somes, TODO EFFICIENT WAY TO DO THIS???\n",
    "allrecipes_df['kcal'] = pd.to_numeric(allrecipes_df['kcal'], errors='coerce')\n",
    "allrecipes_df['carb'] = pd.to_numeric(allrecipes_df['carb'], errors='coerce') / 1000.0 # convert to g\n",
    "allrecipes_df['fat'] = pd.to_numeric(allrecipes_df['fat'], errors='coerce') / 1000.0 # convert to g\n",
    "allrecipes_df['protein'] = pd.to_numeric(allrecipes_df['protein'], errors='coerce')\n",
    "allrecipes_df['sodium'] = pd.to_numeric(allrecipes_df['sodium'], errors='coerce') / 1000.0\n",
    "allrecipes_df['cholesterol'] = pd.to_numeric(allrecipes_df['cholesterol'], errors='coerce')\n",
    "\n",
    "# Remove any rows which isn't properly formatted\n",
    "allrecipes_df = allrecipes_df.dropna()\n",
    "\n",
    "# Remove any duplicated lines\n",
    "allrecipes_df = allrecipes_df.drop_duplicates().set_index('ID')\n",
    "\n",
    "# Printing\n",
    "allrecipes_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing descriptions to Pandas DF\n",
    "allrecipes_desc_df = pd.read_csv(DATA_FOLDER + 'allrecipes_desc.csv', sep='Â£',  header=None, encoding = \"utf-8\",  engine='python')\n",
    "allrecipes_desc_df.columns = ['ID', 'Description']\n",
    "\n",
    "# Remove any duplicated lines\n",
    "allrecipes_desc_df = allrecipes_desc_df.drop_duplicates().set_index('ID')\n",
    "\n",
    "allrecipes_desc_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of recipes:\", len(allrecipes_df.index.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Provided Dataset**\n",
    "\n",
    "This dataset was provided with the assignment and cleaned with the provided `Perl` scripts. \n",
    "\n",
    "Thanks to the scripts, we obtain two datasets:\n",
    "\n",
    "1. `cleaned_ing.csv` contains the list of ingredients for each recipe,\n",
    "2. `cleaned_nutri.csv` contains the corresponding nutritional values.\n",
    "\n",
    "Our objective is to merge these two sets to obtain a unique set with all useful informations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing ingredients to Pandas DF\n",
    "ing_df = pd.read_csv(DATA_FOLDER + 'cleaned_ing.csv', sep='\\t',  header=None, encoding = \"utf-8\")\n",
    "ing_df.columns = ['ID', 'Title', 'Ingredients']\n",
    "\n",
    "# Importing nutritional values to Pandas DF\n",
    "nutri_df = pd.read_csv(DATA_FOLDER + 'cleaned_nutri.csv', sep='\\t',  header=None, encoding = \"utf-8\")\n",
    "nutri_df.columns = ['ID', 'kcal', 'carb', 'fat', 'protein', 'sodium', 'cholesterol']\n",
    "\n",
    "# Merging\n",
    "ing_df = ing_df.set_index('ID')\n",
    "nutri_df = nutri_df.set_index('ID')\n",
    "provided_df = ing_df.merge(nutri_df, on='ID', how='inner')\n",
    "\n",
    "# Drop NaNs and duplicate lines\n",
    "provided_df = provided_df.dropna().drop_duplicates()\n",
    "\n",
    "provided_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that some nutritional values are missing, which can be solved either by removing the lines or by trying to calculate these values from the given ingredients.\n",
    "\n",
    "As trying to calculate the values from ingredients with different units (i.e. grams, cups, tbsp, etc) requires a set of informations that we do not have, we decided to leave these lines as they are for now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bug?? need to convert into numeric somes, TODO EFFICIENT WAY TO DO THIS???\n",
    "provided_df['kcal'] = pd.to_numeric(provided_df['kcal'], errors='coerce')\n",
    "provided_df['carb'] = pd.to_numeric(provided_df['carb'], errors='coerce')\n",
    "provided_df['fat'] = pd.to_numeric(provided_df['fat'], errors='coerce')\n",
    "provided_df['protein'] = pd.to_numeric(provided_df['protein'], errors='coerce')\n",
    "provided_df['sodium'] = pd.to_numeric(provided_df['sodium'], errors='coerce')\n",
    "provided_df['cholesterol'] = pd.to_numeric(provided_df['cholesterol'], errors='coerce')\n",
    "\n",
    "# Insert Region column to match the other DF\n",
    "provided_df.insert(loc=1, column='Region', value=np.nan)\n",
    "provided_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of recipes:\", len(provided_df.index.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the 2 DF and drop any duplicated lines, it is possible since some data come from the same website!\n",
    "recipes_df = allrecipes_df.append(provided_df, sort=False).drop_duplicates()\n",
    "recipes_df['Region'] = recipes_df['Region'].astype('category')\n",
    "\n",
    "recipes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of total recipes:\", len(recipes_df.index.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(recipes_df[recipes_df['Region']=='italian'])/365"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the total number of recipes is enough to eat italian recipes everyday for almost 7 years!!  \n",
    "We can save this DataFrame to be use later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes_df.to_csv(DATA_FOLDER + 'recipes_df.csv', sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Ingredient parsing\n",
    "The cleaning is presented in `DataCleaning.ipynb`, here we use directly the result which is a list of good ingredient that can be matched in the recipes and are relevant for any statistical analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load csv file 'hand' cleaned\n",
    "with open(DATA_FOLDER + 'cleaned_list') as f:\n",
    "    ing_list = f.read().splitlines()\n",
    "    \n",
    "# Load the dictionnary that correct the name mispelled\n",
    "ing_dict = np.load(DATA_FOLDER + 'ing_dict.npy').item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USEFUL\n",
    "recipes_copy = recipes_df.copy()\n",
    "recipes_copy['Ingredients'] = recipes_copy['Ingredients'].str.lower()\n",
    "\n",
    "# Remove non alphabetic values expect of '|' which is the seperating char\n",
    "recipes_copy['Ingredients'] = recipes_copy['Ingredients'].str.replace('[^a-zA-Z ]+', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This step is needed to clean the dataset ingredient!\n",
    "# Function that apply the cleaning dictionnary on every word in ingredients column for each recipes\n",
    "def matcher(k):\n",
    "    x = (i for i in ing_dict if i in k.split(' '))\n",
    "    return '|'.join(map(ing_dict.get, x))\n",
    "\n",
    "# Cleaned!!!\n",
    "recipes_copy['Cleaned_Ing'] = recipes_copy['Ingredients'].map(matcher)\n",
    "recipes_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "**The ingredient list is now perfectly cleaned: we can do some neat analysis on it**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand the cleaned ingredient for each recipes\n",
    "matrix = recipes_copy['Cleaned_Ing'].str.get_dummies('|')\n",
    "# matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numpy array for mathematic manipulations\n",
    "X = matrix.values\n",
    "\n",
    "# Compute the adjacency of the ingredient Graphs\n",
    "# Indeed, since each values belong to the set {0,1}\n",
    "# we get a matrix which corresponds to the number of link\n",
    "# between two ingredients, it is define by the number at a given line - column\n",
    "# TODO explanation\n",
    "\n",
    "adjacency = X.T @ X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph Plotting\n",
    "\n",
    "# TODO: that would be nice https://www.curiousgnu.com/reddit-comments\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "**Test with Holoviews**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=adjacency,    # values\n",
    "...               index=matrix.columns,    # 1st column as index\n",
    "...               columns=matrix.columns)  # 1st row as the column names\n",
    "\n",
    "df = df.unstack().to_frame().reset_index().drop_duplicates()\n",
    "df.columns = ['src', 'trg', 'number']\n",
    "df = df.nlargest(200, columns='number')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import numpy as np\n",
    "import pandas as pd\n",
    "import holoviews as hv\n",
    "hv.extension('bokeh')\n",
    "%output fig='html' size=300\n",
    "\n",
    "%opts Chord [label_index='index' color_index='src' edge_color_index='src'] \n",
    "%opts Chord (cmap='Category20' edge_cmap='Category20')\n",
    "hv.Chord(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count occurences\n",
    "ing_ds = recipes_copy['Ingredients'].str.split(\" \", expand=True) \\\n",
    "                                    .stack() \\\n",
    "                                    .map(ing_dict) \\\n",
    "                                    .value_counts()  \\\n",
    "                                    .to_frame()  \\\n",
    "                                    .reset_index()\n",
    "\n",
    "# TODO THIS SHOULD BE MOVE BELOW, IT IS AN ANALYSIS -> Quite useless but hey :P\n",
    "ing_ds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Try visualization of WordCloud**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ing_ds_region = recipes_copy\n",
    "\n",
    "regions = ing_ds_region['Region'].unique().dropna()\n",
    "\n",
    "top_5_regions = ing_ds_region.groupby('Region').count().sort_values(by='Title', ascending=False).head(5)\\\n",
    ".index.tolist()\n",
    "\n",
    "top_10_regions = ing_ds_region.groupby('Region').count().sort_values(by='Title', ascending=False).head(10)\\\n",
    ".index.tolist()\n",
    "\n",
    "top_15_regions = ing_ds_region.groupby('Region').count().sort_values(by='Title', ascending=False).head(15)\\\n",
    ".index.tolist()\n",
    "\n",
    "\n",
    "recipes_regions = ing_ds_region.groupby('Region').count().sort_values(by='Title', ascending=False)['Title']\n",
    "\n",
    "recipes_regions = recipes_regions.to_frame()\n",
    "\n",
    "recipes_regions.columns = ['Recipe Count']\n",
    "\n",
    "recipes_regions.plot.bar()\n",
    "\n",
    "plt.savefig(\"./website/freelancer-theme/img/recipe_count_per_region.png\", format='png')\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = recipes_copy\n",
    "\n",
    "titles = df.Title.tolist()\n",
    "\n",
    "titles = ''.join(titles)\n",
    "\n",
    "wordcloud = WordCloud(background_color=\"white\", mode=\"RGBA\", max_words=1000, width=800, height=400)\\\n",
    ".generate(titles)\n",
    "\n",
    "print(mask.shape)\n",
    "# create coloring from image\n",
    "plt.figure(figsize=[10,10])\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "# store to file\n",
    "plt.savefig(\"./website/freelancer-theme/img/Flags/titles_wordcloud.svg\", format=\"svg\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingredients_per_region_list = []\n",
    "for region in regions:\n",
    "    ing_ds_region_2 = ing_ds_region[ing_ds_region['Region'] == region]['Ingredients'].str.split(\" \", expand=True) \\\n",
    "                                                                    .stack() \\\n",
    "                                                                    .map(ing_dict) \\\n",
    "                                                                    .value_counts()  \\\n",
    "                                                                    .to_frame()  \\\n",
    "                                                                    .reset_index()\n",
    "    ing_ds_region_2['Region'] = region\n",
    "    ingredients_per_region_list.append(ing_ds_region_2)\n",
    "\n",
    "ingredients_per_region = pd.concat(ingredients_per_region_list)\n",
    "ingredients_per_region = ingredients_per_region.set_index('Region')\n",
    "ingredients_per_region.columns = ['Ingredient', 'Count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_region_ing(region):\n",
    "    ingredients = ingredients_per_region[ingredients_per_region.index == region]\n",
    "    return dict(zip(ingredients['Ingredient'], ingredients['Count']))\n",
    "    \n",
    "\n",
    "for region in top_5_regions:\n",
    "    ing_list = get_region_ing(region)\n",
    "    # Generate a word cloud image\n",
    "    mask = np.array(Image.open(\"Masks/\"+region+\".png\"))\n",
    "\n",
    "    wordcloud = WordCloud(background_color=\"white\", mode=\"RGBA\", max_words=1000, mask=mask, width=800, height=400)\\\n",
    "    .generate_from_frequencies(ing_list)\n",
    "\n",
    "    print(mask.shape)\n",
    "    # create coloring from image\n",
    "    image_colors = ImageColorGenerator(mask)\n",
    "    plt.figure(figsize=[10,10])\n",
    "    plt.imshow(wordcloud.recolor(color_func=image_colors), interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    # store to file\n",
    "    plt.savefig(\"./website/freelancer-theme/img/Flags/\"+region+\"_ing.svg\", format=\"svg\")\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Try visualization with holoviews**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ingredients_per_region.reset_index()\n",
    "top_ingredients_list = []\n",
    "\n",
    "for region in regions:\n",
    "    # Select 50 most used ingredients\n",
    "    top_ingredients = df[df['Region'] == region].head(50)\n",
    "    top_ingredients_list.append(top_ingredients)\n",
    "    \n",
    "top_ingredients = pd.concat(top_ingredients_list)\n",
    "\n",
    "\n",
    "def compare_lists_ing(list1, list2):\n",
    "    '''This function finds how many ingredients are in both lists'''\n",
    "    counter = 0\n",
    "    for ingredient in list1:\n",
    "        if ingredient in list2:\n",
    "            counter += 1\n",
    "    return counter\n",
    "\n",
    "coeff = []\n",
    "region_1 = []\n",
    "region_2 = []\n",
    "\n",
    "# Create a list of coefficients between different regions\n",
    "for i, region1 in enumerate(top_15_regions):\n",
    "    for j, region2 in enumerate(top_15_regions):\n",
    "        if region1 != region2:\n",
    "            list1 = top_ingredients[top_ingredients['Region'] == region1]['Ingredient'].tolist()\n",
    "            list2 = top_ingredients[top_ingredients['Region'] == region2]['Ingredient'].tolist()\n",
    "            \n",
    "            region_1.append(region1)\n",
    "            region_2.append(region2)\n",
    "            coeff.append(compare_lists_ing(list1, list2))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log\n",
    "coeff_log = [int(0.001*(x)**4+0.001*(x)**2-400) for x in coeff]\n",
    "\n",
    "df = pd.DataFrame({'Region 1': region_1, 'Region 2': region_2, 'Coeff': coeff_log})  \n",
    "\n",
    "top_regions_df = pd.DataFrame({'Region': top_15_regions})\n",
    "\n",
    "top_regions_df, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import holoviews as hv\n",
    "hv.extension('bokeh')\n",
    "%output fig='html' size=200\n",
    "\n",
    "%opts Chord [label_index='Region' color_index='Region' edge_color_index='Region 2'] \n",
    "%opts Chord (cmap='Category20' edge_cmap='Category20')\n",
    "nodes = hv.Dataset(top_regions_df, 'Region')\n",
    "\n",
    "chord = hv.Chord((df, nodes), ['Region 1', 'Region 2'], ['Coeff'])\n",
    "\n",
    "renderer = hv.renderer('bokeh')\n",
    "\n",
    "plot = renderer.get_plot(chord).state\n",
    "\n",
    "from bokeh.io import output_file, save, show\n",
    "save(plot, './website/freelancer-theme/img/ingredients_chord.html')\n",
    "show(plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Copy of the df with all the ingredients per region\n",
    "ingredients_per_region_copy = ingredients_per_region.reset_index()\n",
    "\n",
    "#Compute the total number of ingredients per region\n",
    "total_count_per_region = ingredients_per_region_copy.groupby('Region').agg('sum').reset_index()\n",
    "\n",
    "#Create a dict  to divide later\n",
    "dic_prop = dict(zip(total_count_per_region.Region,total_count_per_region.Count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prop_ing(df,dic):\n",
    "    results=[]\n",
    "    for i in range(len(df)):\n",
    "        results.append(df['Count'][i]/dic[df['Region'][i]])\n",
    "    df['Proportion']=results\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Define the proportion of each ingredient per country\n",
    "proportion_df = prop_ing(ingredients_per_region_copy,dic_prop)\n",
    "proportion_df.head(12)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ingredient frequency in the world\n",
    "world_prop=ingredients_per_region.groupby('Ingredient').agg('sum').reset_index()\n",
    "\n",
    "#Compute the total count of the ingredients\n",
    "total_count = sum(world_prop.Count)\n",
    "\n",
    "#Compute the frequency of each ingredients\n",
    "world_prop['Frequency']=world_prop['Count']/total_count\n",
    "\n",
    "world_prop.sort_values('Frequency', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Cooking time study-case\n",
    "\n",
    "In this part we would like to analyze the cooking time of the recipes to be able to classify which regions have the highest and lowest cooking time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all timing from recipes\n",
    "timing_df = allrecipes_desc_df['Description'].str.extractall(r'(\\d+) minutes|(\\d+) hour|hours')\n",
    "timing_df.columns = ['minutes', 'hours']\n",
    "\n",
    "#Replace Nan by 0 and switch to int type\n",
    "timing_df = timing_df.fillna(0).astype(int)\n",
    "\n",
    "#Sum the number of minutes to get the recipe time\n",
    "timing_df['Time (min)'] = timing_df['minutes']+timing_df['hours']*60\n",
    "\n",
    "timing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Sum the total amount of time for each recipe\n",
    "time_recipe = timing_df.groupby('ID').agg('sum')\n",
    "time_recipe = time_recipe.drop(['minutes','hours'], axis=1)\n",
    "\n",
    "time_recipe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Merging\n",
    "Finally, we can merge everything to a single DataFrame to use it for Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging Cooking Time\n",
    "cleaned_df = recipes_df.merge(time_recipe, on='ID', how='left')\n",
    "\n",
    "# Cleaning ingredient and ingredient substition\n",
    "# This is not yet implemented but we are close to achieve this\n",
    "\n",
    "cleaned_df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Analysis\n",
    "\n",
    "This part presents some basic statistical analysis of the data.\n",
    "\n",
    "First we analyse the data by region and observe *mean*, *median*, *min* and *max* for each nutritional value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some classic analysis\n",
    "stats_regions = cleaned_df.groupby('Region')\n",
    "stats_regions = stats_regions.agg({'kcal' : ['mean', 'median', 'min', 'max'],\n",
    "                                       'carb' : ['mean', 'median', 'min', 'max'],\n",
    "                                       'fat' : ['mean', 'median', 'min', 'max'],\n",
    "                                       'protein' : ['mean', 'median', 'min', 'max'],\n",
    "                                       'sodium' : ['mean', 'median', 'min', 'max'],\n",
    "                                       'cholesterol' : ['mean', 'median', 'min', 'max'],\n",
    "                                       'Time (min)' : ['mean', 'median', 'min', 'max']})\n",
    "stats_regions.sort_values([('kcal', 'mean')], ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Visualization\n",
    "\n",
    "In this part we present the overall visualization of informations we retrieve in the dataset.\n",
    "\n",
    "###  Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive plot of correlation between nutritive values \n",
    "def f(nutritive1, nutritive2):\n",
    "    \n",
    "    sns.set_context(\"notebook\", font_scale=1.5)\n",
    "    sns.scatterplot(cleaned_df[nutritive1], cleaned_df[nutritive2])\n",
    "    plt.show()\n",
    "    \n",
    "# Interact\n",
    "interact(f, nutritive1=['kcal', 'carb', 'fat', 'protein', 'sodium', 'cholesterol'],\n",
    "            nutritive2=['kcal', 'carb', 'fat', 'protein', 'sodium', 'cholesterol']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the plot above we can see the correlation between the different nutritional values. \n",
    "\n",
    "For example, there are many recipes where high carbs and fats correspond to high caloric plates, but less so for high proteins. Also it would seem that fats and cholesterol are not as correlated as we would think.\n",
    "\n",
    "Below is a plot that shows the correlation coefficient for pairs of nutritional values by region. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation between nutritional values shown per region\n",
    "def f(region):\n",
    "    sns.set_context(\"notebook\", font_scale=1.5)\n",
    "    \n",
    "    # .iloc[:,:-1] is to avoid the Time column\n",
    "    # It can be interesting to see if there is a correlation\n",
    "    corr = cleaned_df.iloc[:,:-1][cleaned_df['Region'] == region].corr()\n",
    "    sns.heatmap(corr, \n",
    "            xticklabels=corr.columns.values,\n",
    "            yticklabels=corr.columns.values)\n",
    "plt.show()\n",
    "    \n",
    "# Interact\n",
    "interact(f, region=cleaned_df.Region.unique().dropna());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a plot that shows the statistics by nutritional or time value of recipes classified by region. The plot is automatically ordered by median, so we obtain the region with the highest median for that item value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Item value statistics by regions\n",
    "def f(item):\n",
    "    recipe_sorted = stats_regions.sort_values([(item, 'median')], ascending=False)\n",
    "\n",
    "    sns.set_context(\"notebook\", font_scale=1.5)\n",
    "    sns.boxplot(cleaned_df[item], cleaned_df['Region'], order=recipe_sorted.index)\n",
    "    \n",
    "    ## There is a big outlier for Sodium & Time, we will handle it later\n",
    "    if(item == 'sodium'):\n",
    "        plt.xlim(-0.5, 10)\n",
    "        \n",
    "    if(item == 'Time (min)'):\n",
    "        plt.xlim(-50, 1500)\n",
    "    ##\n",
    "    plt.show()\n",
    "    \n",
    "# Interact\n",
    "plt_interact = interact(f, item=['kcal', 'carb', 'fat', 'protein', 'sodium', 'cholesterol', 'Time (min)']);\n",
    "embed_minimal_html('export.html', views=[plt_interact], title='Widgets export')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the most calorical, fat and protein rich recipes belong to Malaysia, while the sodium intake is won by the korean recipes. The ones that have to be most careful about the cholesterol intake seem to be the French.\n",
    "\n",
    "By comparing the median we also see that the longest cooking time and preparation in total is for Persian recipes, whereas Japanese's recipes are the shortest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading JSON of world map\n",
    "map_recipes_json = json.load(open(DATA_FOLDER + 'recipes_map.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer_colormap(topojson, df, column, colorscale):\n",
    "    \n",
    "    # Create a layer\n",
    "    feature_map = folium.FeatureGroup(name=column, overlay=False)  \n",
    "    \n",
    "    def style_function(feature):\n",
    "    # Fetching values for the mean of the category for the given asked continent\n",
    "        value = df[df['Region'] == feature['properties']['Region']][column].mean()\n",
    "        return {\n",
    "            'color': 'black',\n",
    "            'weight': 1,\n",
    "            'fillOpacity': 0.5,\n",
    "            'fillColor': '#black' if np.isnan(value) else colorscale(value)\n",
    "                }\n",
    "    # Fetch values from the DataFrame and apply the colormap to the values\n",
    "    # If the value is NaN, the corresponding color is dark-grey\n",
    "    folium.GeoJson(topojson, style_function=style_function).add_to(feature_map)\n",
    "\n",
    "    return feature_map;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new empty map\n",
    "map_info  = folium.Map([30,0], tiles='cartodbpositron', zoom_start=2)\n",
    "\n",
    "# Add for each nutritive information the map\n",
    "for category in ['kcal','carb','fat','protein','sodium','cholesterol', 'Time (min)']:\n",
    "    colorscale = branca.colormap.linear.YlOrRd_09.scale((min(stats_regions[category]['mean'])), max(stats_regions[category]['mean']))\n",
    "    layer_colormap(map_recipes_json, cleaned_df, category, colorscale).add_to(map_info)\n",
    "    \n",
    "# Add a legend to the colormap and append it to the base layer\n",
    "colorscale.caption = 'Mean of the nutritive value selected'\n",
    "map_info.add_child(colorscale) \n",
    "\n",
    "# Adding the tile Layer thus it is prettier\n",
    "folium.TileLayer(tiles='cartodbpositron', overlay=True).add_to(map_info)\n",
    "\n",
    "# Layer Control to select the different layer created before\n",
    "folium.LayerControl(collapsed=False, position='bottomleft').add_to(map_info);\n",
    "\n",
    "# Save/Display\n",
    "map_info.save('map_info.html')\n",
    "#map_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%HTML\n",
    "<iframe src=\"map_info.html\" width=100% height=700></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the previous map, we can see how the different nutritive properties of the recipes vary through the different continents. We can thus see some correlations like the kcal of the recipe and the fat which are both high in the same continents.  \n",
    "\n",
    "**Note:** we actually have a small issue with the colormap and we will be fixing it by using a different kind of interactive map to show more interesting information (Ingredients distribution, min/max or median for nutrition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##FINAL MAP \n",
    "import geopandas as gpd\n",
    "\n",
    "#Define a geopandas df\n",
    "df_geo = gpd.read_file((DATA_FOLDER + 'recipes_map.json'))\n",
    "\n",
    "#Dissolve the geopandas df into region\n",
    "region_geo = df_geo.dissolve(by='Region')\n",
    "region_geo.head()\n",
    "\n",
    "#Assign two column with the polygon center\n",
    "region_geo['x'] = region_geo.centroid.map(lambda p: p.x)\n",
    "region_geo['y'] = region_geo.centroid.map(lambda p: p.y)\n",
    "region_geo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we assign the text to the corresponding Region\n",
    "stats_regions_copy = stats_regions.reset_index()\n",
    "\n",
    "#First we create one level column index\n",
    "stats_regions_copy.columns = stats_regions_copy.columns.map('_'.join)\n",
    "\n",
    "for col in stats_regions_copy.columns:\n",
    "    stats_regions_copy[col] = stats_regions_copy[col].astype(str)\n",
    "\n",
    "#We create a text with all the column \n",
    "stats_regions_copy['text'] = stats_regions_copy['Region_'] + '<br>' +\\\n",
    "    'Kcal '+stats_regions_copy['kcal_median']+' Carbone '+stats_regions_copy['carb_median']+'<br>'+\\\n",
    "    ' Fat '+stats_regions_copy['fat_median']+' Protein ' + stats_regions_copy['protein_median']+'<br>'+\\\n",
    "    ' Sodium '+stats_regions_copy['sodium_median']+' Cholesterol '+stats_regions_copy['cholesterol_median']\n",
    "    \n",
    "\n",
    "#Add the text to the geopandas df\n",
    "list_text = stats_regions_copy.text.tolist()\n",
    "region_geo['Text']=list_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a map\n",
    "stats_map = folium.Map([30,0], tiles='cartodbpositron', zoom_start=2)\n",
    "\n",
    "#Create an empty list of Markers\n",
    "from folium.plugins import MarkerCluster\n",
    "marker_cluster = MarkerCluster().add_to(stats_map)\n",
    "\n",
    "# Add the coordinates to the Polygon Marker\n",
    "for idx, row in region_geo.iterrows():\n",
    "    # Get lat and lon of points\n",
    "    lon = row['x']\n",
    "    lat = row['y']\n",
    "\n",
    "    # Get address information\n",
    "    text = row['Text']\n",
    "    # Add marker to the map\n",
    "    folium.RegularPolygonMarker(location=[lat, lon], popup=text, fill_color='#2b8cbe', number_of_sides=6, radius=8).add_to(marker_cluster)\n",
    "    \n",
    "#Plot the map \n",
    "stats_map\n",
    "\n",
    "stats_map.save('stats_map.html')\n",
    "#map_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%HTML\n",
    "<iframe src=\"stats_map.html\" width=100% height=700></iframe>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Map with the 10 most popular ingredients per region \n",
    "ten_imp_ing = proportion_df.groupby('Region').apply(lambda x: x.nlargest(10,['Proportion']))\n",
    "ten_imp_ing.head()\n",
    "\n",
    "ten_imp_df = ten_imp_ing.groupby('Region').agg({'Ingredient':lambda x:', '.join(x)})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_geo_ing = region_geo.copy()\n",
    "\n",
    "list_ing = ten_imp_df.Ingredient.tolist()\n",
    "region_geo_ing['Ingredient'] = list_ing\n",
    "region_geo_ing.head()                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a map\n",
    "ing_map = folium.Map([30,0], tiles='cartodbpositron', zoom_start=2)\n",
    "\n",
    "#Create an empty list of Markers\n",
    "from folium.plugins import MarkerCluster\n",
    "marker_cluster2 = MarkerCluster().add_to(ing_map)\n",
    "\n",
    "# Add the coordinates to the Polygon Marker\n",
    "for idx, row in region_geo_ing.iterrows():\n",
    "    # Get lat and lon of points\n",
    "    lon = row['x']\n",
    "    lat = row['y']\n",
    "\n",
    "    # Get address information\n",
    "    text = row['Ingredient']\n",
    "    # Add marker to the map\n",
    "    folium.RegularPolygonMarker(location=[lat, lon], popup=text, fill_color='#2b8cbe', number_of_sides=6, radius=8).add_to(marker_cluster2)\n",
    "    \n",
    "\n",
    "ing_map.save('ing_map.html')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%HTML\n",
    "<iframe src=\"ing_map.html\" width=100% height=700></iframe>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SEARCH FOR A SPECIFIC RECIPE GIVEN A LIST OF ING\n",
    "def search(df, words):  #1\n",
    "    \"\"\"\n",
    "    Return a sub-DataFrame of those rows whose Name column match all the words.\n",
    "    \"\"\"\n",
    "    return df[np.logical_and.reduce([df['Ingredients'].str.contains(word) for word in words])] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('Enter the list of ingredients and let Captain Cook look for a special recipe !')\n",
    "answer = input()\n",
    "answer = answer.split()\n",
    "    \n",
    "\n",
    "recipe_list = search(recipes_copy,answer)\n",
    "if recipe_list.empty == True:\n",
    "    print ('Sorry but we have not recipe with all these ingredients')\n",
    "else:\n",
    "    print ('Here are your recipes !!')\n",
    "recipe_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
