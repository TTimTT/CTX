{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO Markdown title here and explaination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os.path\n",
    "import uritools\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pyspark.sql import *\n",
    "import pyspark.sql.functions as f # wierd that I have to do that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General parameters\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn')#switch to seaborn style\n",
    "plt.rcParams[\"figure.figsize\"] = [16,10]\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "DATA_FOLDER = './data/'\n",
    "RECIPES_PATH = DATA_FOLDER + 'recipePages/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Banana Muffins I Recipe - Allrecipes.com'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: for loop\n",
    "html_string = RECIPES_PATH + '0a7e6e2cae6d4da800d13ef59e760dd3.html'\n",
    "html = open(html_string,'r')\n",
    "soup = BeautifulSoup(open(html_string), 'html.parser')\n",
    "re.sub(r'\\n|\\t', '',soup.title.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Banana Muffins I Recipe - Allrecipes.com'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Title of the recipe, TODO remove the website name?\n",
    "re.sub(r'\\n|\\t', '',soup.title.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ingredients: ['1 cup all-purpose flour', '1 tablespoon baking powder', '1/2 teaspoon baking soda', '1/4 teaspoon salt', '1 cup mashed ripe banana', '1/4 cup white sugar', '1/4 cup sour cream', '1 egg', '1/2 teaspoon vanilla extract']\n",
      "\n",
      "Nutrition: {'calories': '88', 'fat': '1.6g', 'cholesterol': '20mg', 'sodium': '194mg', 'totalcarbs': '16.9g', 'dietaryfiber': '0.8g', 'protein': '2g'}\n",
      "\n",
      "Average ratings: 4.3 Number of vote: 263\n"
     ]
    }
   ],
   "source": [
    "# def scrap_AllRecipe_com( soup )\n",
    "# Get All the ingredients\n",
    "ingredient_list = list()\n",
    "for tag in soup.findAll(\"li\", {\"class\": re.compile('.*ingredient*', flags=re.IGNORECASE)}):\n",
    "    ingredient_list.append(re.sub(r'\\n|  ', '', tag.text))\n",
    "            \n",
    "# Printing  ingredients\n",
    "print(\"\\nIngredients:\",ingredient_list)\n",
    "\n",
    "## How to append to list?\n",
    "# If 'banana' doesnt exist in the list -> add mashed ripe banana to the list\n",
    "# if afterwards we see banana, by regex matching we should get back mashed ripe banana, in this case we rename\n",
    "# the mashed ripe to banana ( comparing the size of the keywords)\n",
    "\n",
    "# Fetch nutritional information\n",
    "# TODO, we can get WAY MORE if you look just below in the website\n",
    "# how can we store all the informations if somes are missing?\n",
    "nutritive_info = soup.findAll(True, {\"id\": re.compile('.*nutri*.', flags=re.IGNORECASE)})\n",
    "\n",
    "# Sub Extracting nutritive informations per Serving\n",
    "soup_nutrition = BeautifulSoup(str(nutritive_info), 'html.parser')\n",
    "\n",
    "# Awesome!!!! TODO\n",
    "nutrition_dict = {}\n",
    "for tag in soup_nutrition.findAll('span'):\n",
    "    nutrition_dict.update({tag.get(\"class\")[0]: tag.text})\n",
    "\n",
    "# Printing nutrition\n",
    "print(\"\\nNutrition:\", nutrition_dict)\n",
    "\n",
    "# Ratings\n",
    "rating = re.search(r'AverageRating\":(\\d+\\.\\d+)',soup.text, re.IGNORECASE).group(1)\n",
    "n_rating = soup.findAll(\"span\", {\"class\": \"count\"})[0].text\n",
    "\n",
    "print(\"\\nAverage ratings:\", rating, \"Number of vote:\", n_rating)\n",
    "\n",
    "# return ingredient_list, nutrition_dict, rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flow chart\n",
    "# CHeck every website name\n",
    "# create for each website a dedicated function to fetch informations\n",
    "# Keep in mind to avoid empty recipes website ( as index pages)\n",
    "# save all this to a pysprk parquet file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n"
     ]
    }
   ],
   "source": [
    "# For each file we first look at every possiblr website\n",
    "website_titles= {}\n",
    "\n",
    "files = os.listdir(RECIPES_PATH)\n",
    "for filename in files:\n",
    "    \n",
    "    # Opening HTML file\n",
    "    with open(RECIPES_PATH + filename, 'rb') as file:\n",
    "        try:\n",
    "            # Parsing the HTML file\n",
    "            soup = BeautifulSoup(file, 'html.parser')\n",
    "    \n",
    "            # Retrieve the HostName\n",
    "            hostname = uritools.urisplit(soup.find('a',href=True)['href']).gethost()\n",
    "    \n",
    "            # Append the HostName if not seen yet\n",
    "            website_titles.update({hostname: filename})\n",
    "            \n",
    "        except : # whatever reader errors you care about\n",
    "            continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
