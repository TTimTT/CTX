{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data acquisition and cleaning\n",
    "**This part is only dedicated to how the data was acquired and cleaned**\n",
    "This notebook isn't suppose to be executed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have two sources of data:\n",
    "- Provided data from ICC\n",
    "- Crawled data from web"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process of the provided data\n",
    "The provided data was easily parsed with the `Perl` script given by the TA, no cleaning was necessary here, removing NaN values and dropping duplicates is done when loading the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process of the crawled data\n",
    "We used several own-made `BASH` script to fetch and retrieve data from a given website.\n",
    "\n",
    "The first was made by hand (the structure of the folders was done with `wget -x`): we retrieve each category of regional cuisines and create separated folders. In each folder there was the **index.html** page of the corresponding regional cuisine page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, by using the following script, we retrieve links for each category we had previously found:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetcher.sh\n",
    "#!/usr/bin/env bash\n",
    "STARTING=$PWD\n",
    "for directory in $(find $STARTING -type d); \n",
    "do\n",
    "    cd \"$directory\"\n",
    "    url=$(cat *.html* | grep \"canonical*\"  | sed \"s/.*href=\\\"//\" | sed \"s/\\\" \\/>/?page=/\")\n",
    "\n",
    "    $STARTING/./crawling.sh $url 2\n",
    "    sleep 5\n",
    "    cd $STARTING\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crawling.sh\n",
    "#!/usr/bin/env bash\n",
    "for i in $(eval echo {1..$2})\n",
    "do\n",
    " TARGET=\"${1/$'\\r'/}$i\"\n",
    "    --wait=10 \\\n",
    "    --random-wait \\\n",
    "    --reject '*.js,*.css,*.ico,*.gif,*.jpg,*.jpeg,*.png,*.mp3,*.pdf,*.tgz,*.flv,*.avi,*.mpeg,*.iso' \\\n",
    "    --execute robots=off \\\n",
    "    --user-agent=AGENT \\\n",
    "    --convert-links \\\n",
    "    --no-cache \\\n",
    "    --no-clobber \\\n",
    "    --no-http-keep-alive \\\n",
    "    --follow-tags=a/href \\\n",
    "    --accept=html \\\n",
    "    --header=\"Accept: text/html\" \\\n",
    "    --ignore-tags=img,link,script \\\n",
    "    $TARGET\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this first step, we had a *urls.txt* file for each subfolder, which has all the recipes link for a given category.  \n",
    "Last step was to execute for each line the following script.  \n",
    "It downloads the page into a temporary `HTML` file, retrieves the required data and timeouts for 5 seconds to avoid the website robot to detect us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env bash\n",
    "\n",
    "STARTING=$PWD\n",
    "TMP_FILE=\"tmp.html\"\n",
    "DATA_FILE=\"data.csv\"\n",
    "DESC_FILE=\"desc.csv\"\n",
    "URL_LISTS=\"urls.txt\"\n",
    "\n",
    "for directory in $(find $STARTING -type d); \n",
    "do\n",
    "    cd \"$directory\"\n",
    "    for url in $(cat $URL_LISTS)\n",
    "    do\n",
    "        #################################### Downloading\n",
    "        wget \\\n",
    "            --wait=10 \\\n",
    "            --random-wait \\\n",
    "            --reject '*.js,*.css,*.ico,*.gif,*.jpg,*.jpeg,*.png,*.mp3,*.pdf,*.tgz,*.flv,*.avi,*.mpeg,*.iso' \\\n",
    "            --execute robots=off \\\n",
    "            --user-agent=AGENT \\\n",
    "            --convert-links \\\n",
    "            --no-cache \\\n",
    "            --no-clobber \\\n",
    "            --no-http-keep-alive \\\n",
    "            --output-document=\"$TMP_FILE\" \\\n",
    "            \"$url\"\n",
    "\n",
    "        #################################### Parsing\n",
    "        # Main info -> inggredients\n",
    "        hash=$(md5sum $TMP_FILE | sed \"s/  $TMP_FILE.*//\")\n",
    "        title=$(cat $TMP_FILE | grep \"<title>\" | sed \"s/.*<title>//\" | sed \"s/Recipe - Allrecipes.*//\")\n",
    "        ing=$(cat $TMP_FILE | grep \"checkList__item'\\}\\[true\\]\" | sed \"s/.*title=\\\"//\" | sed \"s/\\\">//\" | tr \"\\r\" \" \" | tr \"\\n\" \"|\")\n",
    "\n",
    "        # Nutritive\n",
    "        nutritive=$(cat $TMP_FILE | grep -A 20 \"<div class=\\\"nutrition-summary-facts\\\">\" | grep \"itemprop\")\n",
    "\n",
    "        # Calories values\n",
    "        cal=$(echo \"$nutritive\" | grep \"calorie*\" | sed 's/<span itemprop=\\\"calories\\\">//' | sed \"s/ calories;<\\/span.*//\" | sed 's/[[:blank:]]//g' | sed ':a;N;$!ba;s/\\n//g')\n",
    "\n",
    "        # Fat values\n",
    "        fat=$(echo \"$nutritive\" |grep \"fat*\")\n",
    "        val=$(echo \"$fat\" | sed 's/<span itemprop=\\\"fatContent\\\">//' | sed \"s/<span.*//\" | sed 's/[[:blank:]]//g' | sed ':a;N;$!ba;s/\\n//g')\n",
    "        if [[ $val ]]\n",
    "        then\n",
    "            if [[ $(echo \"$fat\" | sed \"s/.*hidden=\\\"true\\\">//\" | grep \"mg\") ]]\n",
    "            then\n",
    "                fat=$val\n",
    "            else\n",
    "                fat=$(echo $val*1000 | bc)\n",
    "            fi\n",
    "        fi\n",
    "\n",
    "        # Carbon values\n",
    "        carb=$(echo \"$nutritive\" |grep \"carbon*\")\n",
    "        val=$(echo \"$carb\" | sed 's/<span itemprop=\\\"carbohydrateContent\\\">//' | sed \"s/<span.*//\" | sed 's/[[:blank:]]//g' | sed ':a;N;$!ba;s/\\n//g')\n",
    "        if [[ $val ]]\n",
    "        then\n",
    "            if [[ $(echo \"$carb\" | sed \"s/.*hidden=\\\"true\\\">//\" | grep \"mg\") ]]\n",
    "            then\n",
    "                carb=$val\n",
    "            else\n",
    "                carb=$(echo $val*1000 | bc)\n",
    "            fi\n",
    "        fi\n",
    "\n",
    "        # Protein values\n",
    "        prot=$(echo \"$nutritive\" |grep \"prot*\")\n",
    "        val=$(echo \"$prot\" | sed 's/<span itemprop=\\\"proteinContent\\\">//' | sed \"s/<span.*//\" | sed 's/[[:blank:]]//g' | sed ':a;N;$!ba;s/\\n//g')\n",
    "        if [[ $val ]]\n",
    "        then\n",
    "            if [[ $(echo \"$prot\" | sed \"s/.*hidden=\\\"true\\\">//\" | grep \"mg\") ]]\n",
    "            then\n",
    "                prot=$val\n",
    "            else\n",
    "                prot=$(echo $val*1000 | bc)\n",
    "            fi\n",
    "        fi\n",
    "\n",
    "        # Cholesterol values\n",
    "        chol=$(echo \"$nutritive\" |grep \"chol*\")\n",
    "        val=$(echo \"$chol\" | sed 's/<span itemprop=\\\"cholesterolContent\\\">//' | sed \"s/<span.*//\" | sed 's/[[:blank:]]//g' | sed ':a;N;$!ba;s/\\n//g')\n",
    "        if [[ $val ]]\n",
    "        then\n",
    "            if [[ $(echo \"$chol\" | sed \"s/.*hidden=\\\"true\\\">//\" | grep \"mg\") ]]\n",
    "            then\n",
    "                chol=$val\n",
    "            else\n",
    "                chol=$(echo $val*1000 | bc)\n",
    "            fi\n",
    "        fi\n",
    "\n",
    "        # Sodium values\n",
    "        sod=$(echo \"$nutritive\" |grep \"sodium*\")\n",
    "        val=$(echo \"$sod\" | sed 's/<span itemprop=\\\"sodiumContent\\\">//' | sed \"s/<span.*//\" | sed 's/[[:blank:]]//g' | sed ':a;N;$!ba;s/\\n//g')\n",
    "        if [[ $val ]]\n",
    "        then\n",
    "            if [[ $(echo \"$sod\" | sed \"s/.*hidden=\\\"true\\\">//\" | grep \"mg\") ]]\n",
    "            then\n",
    "                sod=$val\n",
    "            else\n",
    "                sod=$(echo $val*1000 | bc)\n",
    "            fi\n",
    "        fi\n",
    "        ######################################### Get Directives\n",
    "        reg=\"<span class=\\\"recipe-directions__list--item\\\">\"\n",
    "        desc=$(cat \"$TMP_FILE\" | grep \"$reg\" | sed \"s/$reg//\" | tr \"\\n\" \" \" | tr -s \" \")\n",
    "        ######################################### Printout\n",
    "        echo -e \"$hash\\t${PWD##*/}\\t$title\\t$ing\\t$cal\\t$carb\\t$fat\\t$prot\\t$sod\\t$chol\" >> \"$DATA_FILE\"\n",
    "        echo -e \"$hashÂ£$desc\" >> $DESC_FILE\n",
    "        #################################### napping\n",
    "        sleep 5\n",
    "    ######################################### end for URLS\n",
    "    done \n",
    "    ######################################### \n",
    "    cd $STARTING\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: we have also retrieved the textual description to make text analysis on it (e.g time of cooking etc..)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
